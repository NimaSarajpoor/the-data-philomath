+++ 
draft = true
date = 2025-11-08T01:00:00-04:00
title = "LLM 102"
description = ""
slug = ""
authors = []
tags = []
categories = []
externalLink = ""
series = []
+++

This is LLM 102! LLM 101 is what I did for my blog. It was simply an API call where a text is passed to Google LLM's model.
The text contains an instruction and the data on which that instrcution should be appied. Now, I am going to use LLM in a more complicated case. Let's say
I have a data, and I want to query information from it. So, this is how it looks like:


user: "THIS IS MY QUERY" --> API <-- DATA

One of the question that came to my mind was: "OK! But, why shouldn't I just do f"THIS IS MY QUERY. use this data: {DATA}"? What can go wrong? 
One limitation seems to be the window size that can be passed as single prompt. Another thing is that you do not have to pass data again and again!
You just pass it once. Let's take a close look to what is happening:

(0) Provided text data -> a certain vectors on n-dim Euclidean space <br>
(1) User: "THIS IS MY QUERY"  -> converted to one (or more?) vectors <br>
(2) Find the similarity between (1) and (0) <br>
(3) Based on those similarity, passed a new prompt to LLM (what if that second prompt is big?). For instance:
"Based on these points: {similar-to-query items}, answer this: {query of user}" <br>
(4) Response is shown to uesr <br>



